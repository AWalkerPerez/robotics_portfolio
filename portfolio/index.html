<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Robotics Portfolio</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Configure Tailwind for custom colors and fonts -->
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        'robot-blue': '#1e40af', // Project 1: Deep blue accent
                        'robot-green': '#059669', // Project 2: Green accent
                        'robot-red': '#dc2626', // Project 3: Red accent
                        'robot-purple': '#7c3aed', // Project 4: Purple accent
                        'robot-gold': '#d97706', // Project 5: Gold accent
                        'robot-light': '#f3f4f6',
                        'robot-dark': '#111827',
                    },
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                }
            }
        }
    </script>
    <style>
        /* Custom styles for professional feel */
        .gradient-text-blue {
            background-image: linear-gradient(to right, #1e40af, #3b82f6);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .gradient-text-green {
            background-image: linear-gradient(to right, #059669, #34d399);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .gradient-text-red {
            background-image: linear-gradient(to right, #dc2626, #f87171);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .gradient-text-purple {
            background-image: linear-gradient(to right, #7c3aed, #a78bfa);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .gradient-text-gold {
            background-image: linear-gradient(to right, #d97706, #fcd34d);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .section-separator {
            width: 100px;
            height: 4px;
            margin: 20px auto;
            background-color: #3b82f6;
            border-radius: 9999px;
        }
    </style>
</head>
<body class="bg-robot-light text-robot-dark font-sans antialiased">

    <div id="app">
        <!-- Navigation Bar -->
        <nav class="bg-robot-dark p-4 shadow-lg sticky top-0 z-10">
            <div class="max-w-7xl mx-auto flex justify-between items-center overflow-x-auto">
                <span class="text-xl font-bold text-white flex-shrink-0 mr-4">Andrea's Robotics Portfolio</span>
                <div class="flex space-x-4 flex-shrink-0">
                    <button id="nav-project1" class="text-white hover:text-robot-blue transition duration-200 font-semibold px-3 py-1 rounded-lg">
                        Project 1: Vision-Guided Arm
                    </button>
                    <button id="nav-project2" class="text-white hover:text-robot-green transition duration-200 font-semibold px-3 py-1 rounded-lg">
                        Project 2: Drawing SCARA Arm
                    </button>
                    <button id="nav-project3" class="text-white hover:text-robot-red transition duration-200 font-semibold px-3 py-1 rounded-lg">
                        Project 3: Line Following Buggy
                    </button>
                    <button id="nav-project4" class="text-white hover:text-robot-purple transition duration-200 font-semibold px-3 py-1 rounded-lg">
                        Project 4: Image-Guided Surgery
                    </button>
                    <button id="nav-project5" class="text-white hover:text-robot-gold transition duration-200 font-semibold px-3 py-1 rounded-lg">
                        Project 5: Sim2Real RL Transfer
                    </button>
                </div>
            </div>
        </nav>

        <!-- Project Content Container -->
        <div id="content-container">
            <!-- Content will be injected here by JavaScript -->
        </div>

    </div>

    <!-- Project 1: Autonomous 3DOF Pick-and-Place Robot (Vision) -->
    <template id="project1-template">
        <div>
            <!-- Header & Hero Section -->
            <header class="py-16 px-4 md:px-8 bg-white shadow-lg">
                <div class="max-w-7xl mx-auto text-center">
                    <span class="text-sm font-semibold uppercase tracking-widest text-robot-blue">Robotics & Computer Vision Project</span>
                    <h1 class="text-5xl md:text-7xl font-extrabold mt-2 leading-tight gradient-text-blue">
                        Autonomous 3DOF Pick-and-Place Robot
                    </h1>
                    <p class="mt-4 text-xl md:text-2xl text-gray-600 max-w-3xl mx-auto">
                        Vision-Guided Control for High-Precision Object Handling in Critical Environments.
                    </p>
                    <!-- Key Metrics -->
                    <div class="mt-10 flex flex-wrap justify-center gap-6">
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-blue">3DOF</p>
                            <p class="text-sm text-gray-500">Degrees of Freedom</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-blue">ROS2</p>
                            <p class="text-sm text-gray-500">Modular Architecture</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-blue">DLS IK</p>
                            <p class="text-sm text-gray-500">Motion Planning Solver</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-blue">~1.14 mm</p>
                            <p class="text-sm text-gray-500">Optimal Placement Error</p>
                        </div>
                    </div>
                </div>
            </header>

            <!-- Section 1: Challenge & Hardware -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">The Challenge: Precision & Safety</h2>
                <div class="md:flex md:space-x-10 items-center">
                    <div class="md:w-1/2 mb-8 md:mb-0">
                        <p class="text-lg text-gray-700 leading-relaxed">
                            Inspired by the demanding environment of surgical tool handling, this project aimed to build a low-cost, high-reliability robotic assistant. The core task was <strong>autonomous pick-and-place</strong>—identifying an object, grasping it, and placing it at a specific target location with sub-millimeter precision, all while dynamically avoiding unexpected obstacles.
                        </p>
                        <h3 class="text-2xl font-semibold mt-6 mb-3 text-robot-blue">Custom Hardware & Setup</h3>
                        <p class="text-base text-gray-700">
                            The system uses a custom-designed 3DOF robotic arm powered by Dynamixel motors. The end-effector is a <strong>3D-printed motorized clamp</strong>, designed specifically for secure and gentle grasping. An overhead Logitech camera provides the essential, high-resolution view of the workspace.
                        </p>
                    </div>
                    <div class="md:w-1/2 relative bg-white p-4 rounded-xl shadow-xl">
			<div class="flex justify-center">
                        	<!-- Main Setup Image -->
                        	<img src="setup_photo.jpg" alt="Full Experimental Setup" class="w-full lg:w-1/3 h-auto object-cover rounded-lg shadow-md">
			</div>
                        <p class="mt-2 text-center text-sm text-gray-500">The full experimental setup with overhead camera and robot base.</p>

                        <!-- Gripper CAD Overlay -->
                        <div class="absolute -top-6 right-0 w-40 h-40 md:w-56 md:h-56 transform translate-x-4 translate-y-4 bg-white p-2 rounded-xl shadow-2xl border-4 border-robot-blue/50 hidden sm:block">
                            <img src="gripper_cad.png" alt="CAD Model of Motorized Gripper" class="w-full h-full object-contain">
                            <span class="absolute -top-3 left-1/2 transform -translate-x-1/2 px-2 py-0.5 text-xs bg-robot-blue text-white rounded-full">End-Effector CAD</span>
                        </div>
                    </div>
                </div>
            </section>

            <div class="section-separator"></div>

            <!-- Section 2: Technical Core & Control Architecture -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto bg-white rounded-xl shadow-xl">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">Intelligence: Vision, Motion, & ROS2</h2>
                <div class="md:flex md:space-x-10 items-start">
                    <!-- Algorithm/Tech Description -->
                    <div class="md:w-1/2 mb-8 md:mb-0">
                        <ul class="space-y-6 text-gray-700">
                            <li class="p-4 border-l-4 border-robot-blue bg-robot-light rounded-md">
                                <span class="text-xl font-semibold text-robot-dark block">Vision-Based Localization (AprilTags)</span>
                                <p class="text-base mt-1">
                                    We used <strong>AprilTags</strong> for robust, real-time 6-DOF pose estimation. Careful camera calibration and coordinate transformation convert 2D image data into precise 3D robot base-frame coordinates, making the object location known.
                                </p>
                            </li>
                            <li class="p-4 border-l-4 border-robot-blue bg-robot-light rounded-md">
                                <span class="text-xl font-semibold text-robot-dark block">Damped Least Squares (DLS) Inverse Kinematics</span>
                                <p class="text-base mt-1">
                                    Motion planning is solved using a Jacobian-based Inverse Kinematics (IK) approach. The <strong>DLS method</strong> ensures the robot's movement is smooth, stable, and navigates gracefully around kinematic singularities—a crucial feature for consistent operation.
                                </p>
                            </li>
                            <li class="p-4 border-l-4 border-robot-blue bg-robot-light rounded-md">
                                <span class="text-xl font-semibold text-robot-dark block">Modular ROS2 Control System</span>
                                <p class="text-base mt-1">
                                    A robust ROS2 architecture distributes tasks across dedicated nodes (`camera_publisher`, `aruco_pose`, `marker_tracking`, `hardware_interface.py`), ensuring scalability, real-time performance, and easy debugging.
                                </p>
                            </li>
                        </ul>
                    </div>
                    <!-- Operational Pipeline Image -->
                    <div class="md:w-1/2 flex justify-center">
                        <div class="w-full max-w-md bg-robot-dark p-6 rounded-xl shadow-2xl">
                            <img src="pipeline_flow.png" alt="Operational Pipeline Flowchart" class="w-full h-auto object-contain rounded-lg">
                            <p class="mt-4 text-center text-sm text-gray-400">Step-by-step pick-and-place execution pipeline.</p>
                        </div>
                    </div>
                </div>
            </section>

            <div class="section-separator"></div>

            <!-- Section 3: Results & Demonstration -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">Operational Demos: Accuracy and Robustness</h2>

                <!-- Demos Grid -->
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">

                    <!-- Video 1: Pick and Place of Multiple Objects -->
                    <div class="bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mb-3 text-robot-blue">High-Precision Pick-and-Place</h3>
                        <video controls class="w-full rounded-lg shadow-md mb-4" poster="https://placehold.co/600x400/1e40af/ffffff?text=Multiple+Objects+Video"
                            src="multiple_objects.mp4"
                            onerror="this.poster='https://placehold.co/600x400/ccfbf1/000000?text=Video+Load+Error';"
                            >
                            Your browser does not support the video tag.
                        </video>
                        <p class="text-base text-gray-700 leading-relaxed">
                            This demonstration showcases the core function: accurately picking up an object and placing it at a predefined target. By optimizing the Damping Factor in the DLS solver (optimal setting achieved <strong>1.14 mm mean error</strong>), we ensured responsiveness while maintaining trajectory stability and consistent precision.
                        </p>
                    </div>

                    <!-- Video 2: Obstacle Avoidance -->
                    <div class="bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mb-3 text-robot-blue">Dual-Layer Collision Detection</h3>
                        <video controls class="w-full rounded-lg shadow-md mb-4" poster="https://placehold.co/600x400/1e40af/ffffff?text=Obstacle+Avoidance+Video"
                            src="obstacle_avoidance.mp4"
                            onerror="this.poster='https://placehold.co/600x400/ccfbf1/000000?text=Video+Load+Error';"
                            >
                            Your browser does not support the video tag.
                        </video>
                        <p class="text-base text-gray-700 leading-relaxed">
                            Safety is paramount. The system implements dual collision checks:
                            <ul class="list-disc list-inside mt-2 ml-4">
                                <li><strong>Vision-Based:</strong> Detects foreign AprilTags in the path, aborts motion, and returns to home position (as shown).</li>
                                <li><strong>Hardware-Based:</strong> Monitors real-time motor current. Exceeding a safe threshold triggers an immediate, emergency stop.</li>
                            </ul>
                        </p>
                    </div>
                </div>
            </section>
        </div>
    </template>

    <!-- Project 2: Al the Drawing Robotic Arm (Kinematics & PID) -->
    <template id="project2-template">
        <div>
            <!-- Header & Hero Section -->
            <header class="py-16 px-4 md:px-8 bg-white shadow-lg">
                <div class="max-w-7xl mx-auto text-center">
                    <span class="text-sm font-semibold uppercase tracking-widest text-robot-green">Mechatronics & Control Systems Project</span>
                    <h1 class="text-5xl md:text-7xl font-extrabold mt-2 py-4 leading-tight gradient-text-green">
                        Al The Drawing Robotic Arm
                    </h1>
                    <p class="mt-4 text-xl md:text-2xl text-gray-600 max-w-3xl mx-auto">
                        Design, Kinematics, and PID Tuning for a High-Precision 2DOF Parallel SCARA Manipulator.
                    </p>
                    <!-- Key Metrics -->
                    <div class="mt-10 flex flex-wrap justify-center gap-6">
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-green">2DOF</p>
                            <p class="text-sm text-gray-500">Parallel SCARA</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-green">Arduino/L298N</p>
                            <p class="text-sm text-gray-500">Low-Cost Control</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-green">PID Control</p>
                            <p class="text-sm text-gray-500">Tuned for Precision</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-green"> 156 &times; 156 mm</p>
                            <p class="text-sm text-gray-500">Precision Workspace</p>
                        </div>
                    </div>
                </div>
            </header>

            <!-- Section 1: Design & Kinematics -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">Mechatronics Design & Kinematic Foundation</h2>
                <div class="md:flex md:space-x-10 items-start">
                    
                    <div class="md:w-1/2 mb-8 md:mb-0 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-green">Parallel SCARA Design</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            The robot was custom-designed as a <strong>2DOF Parallel SCARA manipulator</strong> to maximize workspace usage while ensuring mechanical robustness, ideal for precision tasks like drawing or micro-surgical simulation.
                        </p>
                        <!-- CAD Model Image -->
                        <img src="cad_design.png" alt="Final CAD Design of Drawing Robot" class="w-full h-auto object-cover rounded-lg shadow-md mt-4">
                        <p class="mt-2 text-center text-sm text-gray-500">Final CAD Model in Fusion 360 showing the compact, parallel link structure.</p>

			<!--Final Product Photo -->
			<div class="mt-4 border border-gray-200 p-3 rounded-lg bg-gray-50">
			    <h4 class="text-xl font-semibold text-robot-green mb-2">Final 3D Printed Product</h4>
			    <img src="final_product.png" alt="Final 3D Printed Drawing Robot Arm" class="w-full h-auto object-contain rounded-lg shadow-md">
			    <p class="mt-2 text-center text-sm text-gray-500">The assembled 3D printed arm with pen holder attachment.</p>
			</div> 
                        
                        <h3 class="text-2xl font-semibold mt-6 mb-3 text-robot-green">Hardware & Fabrication</h3>
                        <p class="text-base text-gray-700">
                            The arm was 3D printed using PLA for lightweight strength. It integrates micro servo motors, controlled by an Arduino Uno and an L298N driver. Crucially, thrust and ball bearings were incorporated into the joints to <strong>minimize friction and handle axial loads</strong>, enhancing precision and longevity.
                        </p>
                    </div>

                    <div class="md:w-1/2 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-green">Kinematics & Workspace</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            Accurate motion relies on solving both <strong>Forward and Inverse Kinematics</strong> analytically using geometric and trigonometric relationships. This direct, non-iterative approach ensures rapid, precise joint angle computation for a desired Cartesian coordinate (x, y).
                        </p>
                        <p class="text-base text-gray-700 mt-4">
                            The operational space was tightly defined as a 156 &times; 156 mm square. While the <strong>analytical method</strong> proved fast and precise in the center of the workspace, its performance near singularities was compared against <strong>Jacobian Transpose</strong> and the more stable <strong>Damped Least Squares (DLS)</strong> methods, validating the analytical approach for this fixed-geometry task.
                        </p>
                        <p class="text-center text-xl font-mono mt-4 text-robot-dark">
                            Inverse Kinematics involves calculating &theta;<sub>1</sub>, &theta;<sub>4</sub> from (x, y).
                        </p>
                        <!-- Kinematic Diagram Image Placeholder -->
                        <img src="kinematics_diag.png" alt="Analytical Inverse Kinematics Diagram" class="w-full h-auto object-cover rounded-lg shadow-md mt-4">
                        <p class="mt-2 text-center text-sm text-gray-500">Geometric diagram used to derive the Analytical Inverse Kinematics solution.</p>
                    </div>
                </div>
            </section>

            <div class="section-separator" style="background-color: #059669;"></div>

            <!-- Section 2: Control & Performance -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">Control: PID Tuning & Performance Trade-Offs</h2>
                
                <div class="md:flex md:space-x-10 items-start">
                    
                    <div class="md:w-1/2 mb-8 md:mb-0 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-green">PID Control Optimization</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            A <strong>PID controller</strong> was implemented to ensure smooth, responsive, and precise angular positioning of the micro servos. The controller gains (K<sub>P</sub>, K<sub>I</sub>, K<sub>D</sub>) were systematically tuned to achieve an <strong>optimally damped response</strong>, minimizing overshoot and settling time.
                        </p>
                        
                        <ul class="list-disc list-inside mt-4 ml-4 text-base text-gray-700">
                            <li><strong>Optimal Gains:</strong> K<sub>P</sub>=28, K<sub>I</sub>=10, K<sub>D</sub>=18 (Motor 1) and K<sub>P</sub>=25, K<sub>I</sub>=6, K<sub>D</sub>=18 (Motor 2)</li>
                            <li><strong>Result:</strong> Minimal peak overshoot of 7.93% and a steady-state error of -1.43&deg;.</li>
                        </ul>
                        
                        <!-- PID Graph Placeholder -->
                        <img src="pid_control.png" alt="Optimal PID Response Graph" class="w-full h-auto object-cover rounded-lg shadow-md mt-6">
                        <p class="mt-2 text-center text-sm text-gray-500">Visualizing the optimally damped PID response curve vs. under/overdamped scenarios.</p>

                    </div>

                    <div class="md:w-1/2 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-green">Accuracy and Speed vs. Precision</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            Experimental evaluation quantified the system's performance.
                        </p>
                        <h4 class="text-xl font-semibold mt-4 text-robot-dark">Accuracy Test Results</h4>
                        <ul class="list-disc list-inside mt-2 ml-4 text-base text-gray-700">
                            <li><strong>Average Deviation:</strong> Achieved low deviations near the workspace center (e.g., 2.83 mm).</li>
                            <li><strong>Constraint Observed:</strong> Deviation increased significantly towards the workspace boundaries (up to 85.34 mm), confirming mechanical deflection and reduced manipulability at the extremities.</li>
                        </ul>

			<!-- Accuracy Plot -->
			<div class="mt-6 border borde-gray-200 p-3 rounded-lg bg-gray-50">
			    <h4 class="text-xl font-semibold text-obot-green mb-2">End-Effector Positional Accuracy</h4>
			    <img src="results_points.png" alt="End Effector Desired vs Actual Position Plot" class="w-full h-auto object-contain rounded-lg shadow-md">
			    <p class="mt-2 text-center text-sm text-gray-500">Graph showing End-Effector Desired position vs. Actual position along a square trajectory.</p>
			</div>

                        <h4 class="text-xl font-semibold mt-4 text-robot-dark">Speed vs. Accuracy Trade-Off</h4>
                        <p class="text-base text-gray-700 mt-2">
                            The trade-off between speed and precision was clearly demonstrated by varying K<sub>P</sub>. Lower K<sub>P</sub> resulted in the highest accuracy but the slowest movement (longest settling time), while increasing K<sub>P</sub> drastically cut the response time at the cost of significantly increased positional error. This confirms the critical role of PID tuning for task-specific optimization.
                        </p>
                    </div>
                </div>
            </section>
        </div>
    </template>

    <!-- Project 3: Embedded Systems Line Following Buggy -->
    <template id="project3-template">
        <div>
            <!-- Header & Hero Section -->
            <header class="py-16 px-4 md:px-8 bg-white shadow-lg">
                <div class="max-w-7xl mx-auto text-center">
                    <span class="text-sm font-semibold uppercase tracking-widest text-robot-red">Embedded Systems & Competitive Robotics</span>
                    <h1 class="text-5xl md:text-7xl font-extrabold mt-2 py-4 leading-tight gradient-text-red">
                        Autonomous Line Following Buggy
                    </h1>
                    <p class="mt-4 text-xl md:text-2xl text-gray-600 max-w-3xl mx-auto">
                        High-Speed Navigation and Real-Time Control in a Competitive Environment.
                    </p>
                    <!-- Key Metrics -->
                    <div class="mt-10 flex flex-wrap justify-center gap-6">
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-red">PD Control</p>
                            <p class="text-sm text-gray-500">Stability & Speed</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-red">STM32/mbed OS</p>
                            <p class="text-sm text-gray-500">Microcontroller & OS</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-red">1.1 m/s</p>
                            <p class="text-sm text-gray-500">Max Race Speed</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-red">3rd Fastest</p>
                            <p class="text-sm text-gray-500">Heats Placement</p>
                        </div>
                    </div>
                </div>
            </header>

            <!-- Section 1: Design & Characterization -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">Hardware, Sensor Design, and Chassis</h2>
                <div class="md:flex md:space-x-10 items-start">
                    
                    <div class="md:w-1/2 mb-8 md:mb-0 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-red">Custom Chassis & Sensor Array</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            The buggy chassis was custom-designed in Solidworks and fabricated from <stong>Acetyl</strong> for optimal strength-to-weight ratio. A crucial component was the custom <strong>5-sensor PCB array</strong> using TCRT5000 reflective optical sensors.
                        </p>
                        
                        <h4 class="text-xl font-semibold mt-4 text-robot-dark">Sensor Characterization</h4>
                        <p class="text-base text-gray-700">
                            Extensive testing determined the ideal sensor height (15 mm) and separation (15 mm) for maximum sensitivity and distinction between the white line and black background. The <strong>TCRT5000</strong> was selected for its integrated daylight filter and low dark current, ensuring robust performance regardless of ambient lighting (e.g., passing through a tunnel).
                        </p>
                        
                        <!-- FINAL BUGGY PHOTO -->
                        <div class="mt-4 border border-gray-200 p-3 rounded-lg bg-gray-50">
                            <h4 class="text-xl font-semibold text-robot-red mb-2">Final Assembled Buggy</h4>
                            <img src="buggy_photo.png" alt="Final Assembled Buggy with PCBs and wiring" class="w-full h-auto object-contain rounded-lg shadow-md">
                            <p class="mt-2 text-center text-sm text-gray-500">The final assembled buggy, integrating the custom sensor array and control boards.</p>
                        </div>
                        
                        <h4 class="text-2xl font-semibold mt-6 mb-3 text-robot-red">Design Decisions & Trade-offs</h4>
                        <p class="text-base text-gray-700">
                            The battery was placed at the front, underneath the chassis, to lower the center of gravity and prevent tipping when climbing the 18&deg; ramp, a key design challenge. However, this positioning made battery replacement difficult during heats. The narrow width of the sensor array limited high-speed turning ability.
                        </p>
                    </div>

                    <div class="md:w-1/2 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-red">Technical Gallery: Blueprints & Schematics</h3>
                        
                        <!-- Dynamic Image Gallery -->
                        <div class="grid grid-cols-1 sm:grid-cols-2 gap-4">
                            
                            <div class="bg-robot-light p-3 rounded-lg shadow-inner">
                                <img src="buggy_chassis_cad.png" alt="Chassis CAD Design" class="w-full h-60 object-contain rounded-md border border-gray-300">
                                <p class="text-xs font-semibold text-center mt-2 text-robot-dark">Chassis Design (CAD)</p>
                            </div>
                            
                            <div class="bg-robot-light p-3 rounded-lg shadow-inner">
                                <img src="buggy_schematic.png" alt="Sensor Schematic Diagram" class="w-full h-60 object-contain rounded-md border border-gray-300">
                                <p class="text-xs font-semibold text-center mt-2 text-robot-dark">Sensor Schematic Diagram</p>
                            </div>

                            <div class="bg-robot-light p-3 rounded-lg shadow-inner">
                                <img src="buggy_pcb_layout.png" alt="Custom Sensor PCB Layout" class="w-full h-60 object-contain rounded-md border border-gray-300">
                                <p class="text-xs font-semibold text-center mt-2 text-robot-dark">Custom Sensor PCB Layout</p>
                            </div>
                            
                            <div class="bg-robot-light p-3 rounded-lg shadow-inner">
                                <img src="buggy_wiring.png" alt="Wiring Diagram" class="w-full h-60 object-contain rounded-md border border-gray-300">
                                <p class="text-xs font-semibold text-center mt-2 text-robot-dark">Control Wiring Diagram</p>
                            </div>
                        </div>

                        <h3 class="text-2xl font-semibold mt-6 mb-3 text-robot-red">Embedded System Core</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            The system's intelligence ran on an <strong>STM32F401RE Nucleo Platform</strong> programmed in C++ using <strong>mbed OS</strong>, managing dual-motor control and real-time sensor feedback.
                        </p>
                        <ul class="list-disc list-inside mt-4 ml-4 text-base text-gray-700">
                            <li><strong>Actuation:</strong> Dual DC motors with quadrature encoders (AEAT-601BF06) for precise speed monitoring.</li>
                            <li><strong>Motor Control:</strong> PD control implemented for stability and quick error correction.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <div class="section-separator" style="background-color: #dc2626;"></div>

            <!-- Section 2: Competitive Results & Tuning -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">Competitive Performance and PD Tuning</h2>
                
                <div class="md:flex md:space-x-10 items-start">
                    
                    <div class="md:w-1/2 mb-8 md:mb-0 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-red">Strategic PD Tuning for Race Day</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            The primary challenge was balancing speed and stability, especially on sharp turns and track irregularities.
                        </p>
                        
                        <ul class="list-disc list-inside mt-4 ml-4 text-base text-gray-700">
                            <li><strong>Tuning Strategy:</strong> Two distinct codes were prepared: a safe, slow code (0.6 m/s) for guaranteed marks, and a high-speed code (1.1 m/s) for bonus points.</li>
                            <li><strong>Error Compensation:</strong> Custom code was implemented to reduce sensor noise (by subtracting LED-off readings from LED-on readings) and to feed the last known error to the PD algorithm when the line was temporarily lost (e.g., on small gaps).</li>
                            <li><strong>Final Gains:</strong> Optimal PD gains were tuned to K<sub>P</sub>=0.07 and K<sub>D</sub>=0.05 to minimize the oscillations that often plague line-following robots, allowing it to maintain the highest possible speed on straights.</li>
                        </ul>
                    </div>

                    <div class="md:w-1/2 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-red">Heats Summary: Speed & Reliability</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            The strategic approach paid off in the final competition heats.
                        </p>

			<!-- NEW RACE PHOTO -->
                        <div class="mt-4 mb-4 border border-gray-300 p-2 rounded-lg bg-gray-50">
                            <img src="buggy_race.png" alt="Autonomous Buggy on the track during the race heats" class="w-full h-auto object-contain rounded-md shadow-md">
                            <p class="text-center text-sm text-gray-500 mt-2">The high-speed buggy navigating a curve on the final race track.</p>
                        </div>

                        <h4 class="text-xl font-semibold mt-4 text-robot-dark">Race Performance Highlights</h4>
                        <ul class="list-disc list-inside mt-2 ml-4 text-base text-gray-700">
                            <li><strong>Attempt 1:</strong> Success with the safe, 0.6 m/s code, securing maximum completion marks.</li>
                            <li><strong>Attempt 2:</strong> Risk taken at the pushed speed of 1.1 m/s. The buggy completed the track in <strong>11.6 seconds</strong>, earning the <strong>3rd fastest time</strong> and resulting in <strong>2nd place</strong> overall in the heats.</li>
                        </ul>
                        <p class="text-base text-gray-700 mt-4">
                            This project demonstrates not only technical proficiency in embedded C++ programming and closed-loop control but also effective team management and strategic decision-making under competitive pressure.
                        </p>
                    </div>
                </div>
            </section>
        </div>
    </template>

    <!-- Project 4: Image-Guided Surgical Robotics Pipeline -->
    <template id="project4-template">
        <div>
            <!-- Header & Hero Section -->
            <header class="py-16 px-4 md:px-8 bg-white shadow-lg">
                <div class="max-w-7xl mx-auto text-center">
                    <span class="text-sm font-semibold uppercase tracking-widest text-robot-purple">Medical Robotics & Data Integration</span>
                    <h1 class="text-5xl md:text-7xl font-extrabold mt-2 leading-tight gradient-text-purple">
                        Image-Guided Surgical Robotics Pipeline
                    </h1>
                    <p class="mt-4 text-xl md:text-2xl text-gray-600 max-w-3xl mx-auto">
                        End-to-End Trajectory Planning and Simulation using 3D Slicer, OpenIGTLink, and ROS2.
                    </p>
                    <!-- Key Metrics -->
                    <div class="mt-10 flex flex-wrap justify-center gap-6">
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-purple">3D Slicer</p>
                            <p class="text-sm text-gray-500">Image Processing & Planning</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-purple">OpenIGTLink</p>
                            <p class="text-sm text-gray-500">Real-Time Data Bridge</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-purple">ROS2 / Movelt</p>
                            <p class="text-sm text-gray-500">Robotic Simulation</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-purple">Unit Tested</p>
                            <p class="text-sm text-gray-500">Trajectory Logic</p>
                        </div>
                    </div>
                </div>
            </header>

            <!-- Section 1: End-to-End Pipeline & Architecture -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">Integrated Architecture for Patient-Specific Planning</h2>
                <div class="md:flex md:space-x-10 items-start">
                    
                    <div class="md:w-1/2 mb-8 md:mb-0 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-purple">The Vision: Image-Guided Intervention</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            This project developed a pipeline that connects patient-specific anatomical data (CT/MRI) directly to a neuro-arm robot simulation. The goal is a closed-loop system where segmentation data informs precise trajectory planning, and real-time communication ensures seamless execution in a simulated operating environment.
                        </p>
                        <h4 class="text-xl font-semibold mt-4 text-robot-dark">Core Pipeline Flow</h4>
                        <p class="text-base text-gray-700">The entire system is structured around three key stages, connected by a standardized medical data protocol.</p>
                        <ul class="list-disc list-inside mt-2 ml-4 text-base text-gray-700">
                            <li><strong>3D Slicer:</strong> Image segmentation, path definition, and safety constraint validation.</li>
                            <li><strong>OpenIGTLink:</strong> Real-time, low-latency data transfer of trajectory points.</li>
                            <li><strong>ROS2 / Movelt:</strong> Receiving data, performing coordinate transformations, and planning/simulating robot motion.</li>
                        </ul>
                    </div>

                    <div class="md:w-1/2 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-purple">System Workflow Diagram</h3>
                        <p class="text-center text-sm text-gray-500 mt-2">The closed-loop system architecture.</p>
                        <!-- Image of the Integrated Pipeline Diagram -->
                        <img src="surgical_workflow.png" alt="Integrated Workflow Diagram" class="w-full h-auto object-contain rounded-lg shadow-md mt-4">
                        <p class="mt-2 text-center text-sm text-gray-500">Data flows from Medical Imaging through 3D Slicer, transferred via OpenIGTLink, and executed/simulated in ROS2.</p>
                    </div>
                </div>
            </section>

            <div class="section-separator" style="background-color: #7c3aed;"></div>

            <!-- Section 2: Technical Breakdown and Validation -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">Path Planning, Data Bridge, and Simulation</h2>
                
                <div class="md:grid md:grid-cols-2 lg:grid-cols-3 gap-8">
                    
                    <!-- Feature 1: 3D Slicer Custom Module -->
                    <div class="bg-robot-light p-6 rounded-xl shadow-lg mb-8 md:mb-0 border-t-4 border-robot-purple lg:col-span-2">
                        <h3 class="text-xl font-semibold mb-3 text-robot-purple">Patient-Specific Path Planning & Visualization</h3>
                        <p class="text-base text-gray-700">
                            A custom Python module in <strong>3D Slicer</strong> was developed to define surgical trajectories based on user-selected entry/target fiducials. The core logic ensured anatomical safety and accuracy by checking constraints against segmented patient data.
                        </p>
                        <div class="mt-4 border border-gray-300 p-2 rounded-lg bg-white shadow-md">
                            <img src="slicer_trajectory.png" alt="3D Slicer Trajectory Visualization" class="w-full h-auto object-contain rounded-md">
                            <p class="text-xs text-center text-gray-500 mt-2">Visualization of the optimized trajectory relative to segmented brain structures in 3D Slicer.</p>
                        </div>
                        <ul class="list-disc list-inside mt-4 text-base text-gray-700">
                            <li><strong>Safety Constraints:</strong> Logic enforced target inclusion, avoidance of critical structures (using distance maps), maximum length, and correct cortical entry angles.</li>
                            <li><strong>Core Logic:</strong> Robust conversion between RAS (user visualization) and IJK (voxel analysis) coordinate systems ensured anatomical accuracy.</li>
                        </ul>
                    </div>

                    <!-- Execution Logic Flow (fits well here, showing how Slicer output translates to action) -->
                    <div class="bg-robot-light p-6 rounded-xl shadow-lg mb-8 md:mb-0 border-t-4 border-robot-purple">
                        <h3 class="text-xl font-semibold mb-3 text-robot-purple">High-Level Execution Logic</h3>
                        <div class="mt-2 border border-gray-300 p-2 rounded-lg bg-white shadow-md">
                            <img src="high_level_logic.png" alt="High Level Control Workflow" class="w-full h-auto object-contain rounded-md">
                            <p class="text-xs text-center text-gray-500 mt-2">Diagram representing the flow from high-level input to robotic actuation.</p>
                        </div>
                        <ul class="list-disc list-inside mt-4 text-sm text-gray-600">
                            <li><strong>Validation:</strong> Comprehensive unit tests confirmed all planning logic passed successfully before deployment.</li>
                            <li><strong>Execution:</strong> The planned trajectory points are processed via Inverse Kinematics into joint commands for the robot.</li>
                        </ul>
                    </div>
                </div>
                
                <h3 class="text-3xl font-bold text-center mb-6 mt-10 text-robot-purple">Real-Time Data Bridge & Simulation Validation</h3>

                <div class="md:grid md:grid-cols-2 gap-8">
                    <!-- Feature 2: OpenIGTLink Real-Time Transfer -->
                    <div class="bg-robot-light p-6 rounded-xl shadow-lg border-t-4 border-robot-purple">
                        <h3 class="text-xl font-semibold mb-3 text-robot-purple">OpenIGTLink Data Bridge Validation</h3>
                        <p class="text-base text-gray-700">
                            The communication link utilized <strong>OpenIGTLink</strong>, a protocol standard for image-guided therapy, enabling real-time, low-latency transfer of trajectory points (POSITION and TRANSFORM messages) from Slicer to ROS2.
                        </p>
                        <div class="mt-4 border border-gray-300 p-2 rounded-lg bg-white shadow-md">
                            <img src="igtl_data_validation.png" alt="ROS2 IGTLink Data Validation" class="w-full h-auto object-contain rounded-md">
                            <p class="text-xs text-center text-gray-500 mt-2">Validation screenshot showing real-time coordinate updates received by ROS2 via IGTLink.</p>
                        </div>
                        <ul class="list-disc list-inside mt-4 text-sm text-gray-600">
                            <li><strong>Validation:</strong> Monitored using `ros2 topic echo`, verifying coordinate updates were immediately and accurately received by the <strong>ROS2-IGTLink-Bridge</strong> server node.</li>
                        </ul>
                    </div>

                    <!-- Feature 3: ROS2 Simulation and Control -->
                    <div class="bg-robot-light p-6 rounded-xl shadow-lg border-t-4 border-robot-purple">
                        <h3 class="text-xl font-semibold mb-3 text-robot-purple">ROS2 / Movelt Motion Planning</h3>
                        <p class="text-base text-gray-700">
                            The neuro-arm robot was simulated using a <strong>URDF</strong> model within the <strong>ROS2 Jazzy</strong> environment. Movelt was configured to handle the robot's inverse kinematics and generate collision-free paths.
                        </p>
                        <div class="mt-4 border border-gray-300 p-2 rounded-lg bg-white shadow-md">
                            <img src="rviz2_moveit_planning.png" alt="Rviz2 MoveIt! Planning Visualization" class="w-full h-auto object-contain rounded-md">
                            <p class="text-xs text-center text-gray-500 mt-2">Visualization of the trajectory planning window and the planned path in Rviz2.</p>
                        </div>
                        <ul class="list-disc list-inside mt-4 text-sm text-gray-600">
                            <li><strong>Transformation:</strong> A crucial node transforms trajectory data from Slicer's RAS frame to the robot's ROS2 base\_link frame.</li>
                        </ul>
                    </div>
                </div>
            </section>
        </div>
    </template>

    <!-- Project 5: Sim2Real Transfer of RL Agents for Autonomous MT -->
    <template id="project5-template">
        <div>
            <!-- Header & Hero Section -->
            <header class="py-16 px-4 md:px-8 bg-white shadow-lg">
                <div class="max-w-7xl mx-auto text-center">
                    <span class="text-sm font-semibold uppercase tracking-widest text-robot-gold">AI, RL, & Medical Robotics Research</span>
                    <h1 class="text-5xl md:text-7xl font-extrabold mt-2 leading-tight gradient-text-gold">
                        Sim2Real RL Transfer for Autonomous Thrombectomy
                    </h1>
                    <p class="mt-4 text-xl md:text-2xl text-gray-600 max-w-3xl mx-auto">
                        Benchmarking Advanced Domain Randomisation Strategies for Robust Guidewire Navigation.
                    </p>
                    <!-- Key Metrics -->
                    <div class="mt-10 flex flex-wrap justify-center gap-6">
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-gold">SAC</p>
                            <p class="text-sm text-gray-500">Reinforcement Learning Base</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-gold">DROPO / CDR</p>
                            <p class="text-sm text-gray-500">Sim2Real Transfer Methods</p>
                        </p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-gold">CMA-ES</p>
                            <p class="text-sm text-gray-500">Domain Optimization</p>
                        </div>
                        <div class="p-4 bg-robot-light rounded-xl shadow-md">
                            <p class="text-3xl font-bold text-robot-gold">In Vitro</p>
                            <p class="text-sm text-gray-500">Vascular Phantom Testing</p>
                        </div>
                    </div>
                </div>
            </header>

            <!-- Section 1: Challenge & Approach -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">The Challenge: Bridging the Sim2Real Gap</h2>
                <div class="md:flex md:space-x-10 items-start">
                    
                    <div class="md:w-1/2 mb-8 md:mb-0 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-gold">Autonomous Mechanical Thrombectomy (MT)</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            MT is the gold standard for treating large-vessel stroke, but its complexity and reliance on specialized neurointerventionalists limit access. This project aims to enable full <strong>autonomy</strong> for guidewire navigation using Reinforcement Learning (RL).
                        </p>
                        <p class="text-base text-gray-700 mt-4">
                            The critical barrier is the <strong>Sim2Real gap</strong>: dynamics like vessel stiffness, friction, and elasticity in the simulated environment (`stEVE` / `SOFA`) often do not perfectly match reality, causing RL policies trained in simulation to fail in physical phantoms.
                        </p>

			<!-- High Level RL Framework Diagram -->
			<div class="mt-4 mb-4 borde border-gray-300 p-2 rounded-lg bg-white shadow-md">
			     <img src="rl_framework_overview.png" alt="Simulation-to-Real RL Framework Overview" class="w-full h-auto object-contain rounded-md shadow-md">
			     <p class="text-center text-sm text-gray-500 mt-2">The closed-loop Sim-to-Real framework for autonomous guidewire navigation.</p>
			</div>

                        <h4 class="text-xl font-semibold mt-4 text-robot-dark">Core RL Framework</h4>
                        <p class="text-base text-gray-700">
                            The agent was built on the <strong>Soft Actor-Critic (SAC)</strong> algorithm, chosen for its stability and sample efficiency in continuous control, with a reward function balancing progress and safety constraints (collision penalties).
                        </p>
                    </div>

                    <div class="md:w-1/2 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-gold">Experimental Pipeline & Sim/Real Environments</h3>
                        
                        <!-- Experimental Pipeline Flowchart -->
                        <div class="mt-4 mb-4 border border-gray-300 p-2 rounded-lg bg-white shadow-md">
                            <img src="experimental_pipeline.png" alt="Experimental Pipeline Flowchart" class="w-full h-auto object-contain rounded-md shadow-md">
                            <p class="text-center text-sm text-gray-500 mt-2">The systematic experimental pipeline showing training, in-silico, and in-vitro evaluation stages.</p>
                        </div>
                        
                        <h4 class="text-xl font-semibold mt-4 text-robot-dark">Physical Environment</h4>
                        <div class="grid grid-cols-2 gap-4 mt-2">
                            <div class="col-span-2">
                                <img src="robotic_platform.png" alt="Experimental Robotic Platform" class="w-full h-auto object-contain rounded-md shadow-sm">
                                <p class="text-xs text-center text-gray-500 mt-1">Robotic platform used for in vitro catheter navigation.</p>
                            </div>
                            <div class="col-span-2">
                                <img src="phantom_setup.png" alt="Vascular Phantom Setup and CAD Clamp" class="w-full h-auto object-contain rounded-md shadow-sm">
                                <p class="text-xs text-center text-gray-500 mt-1">Vascular phantom setup inside fluid container, secured by custom CAD clamps.</p>
                            </div>
                        </div>

                        <h4 class="text-xl font-semibold mt-4 text-robot-dark">Simulated Environment</h4>
                        <div class="mt-2">
                            <img src="vascular_geometries.png" alt="Vascular Geometries in Simulation" class="w-full h-auto object-contain rounded-md shadow-sm">
                            <p class="text-xs text-center text-gray-500 mt-1">Example vascular geometries used in the stEVE simulation environment.</p>
                        </div>
                    </div>
                </div>
            </section>

            <div class="section-separator" style="background-color: #d97706;"></div>

            <!-- Section 2: Results & Benchmarking -->
            <section class="py-16 px-4 md:px-8 max-w-7xl mx-auto">
                <h2 class="text-4xl font-bold text-center mb-10 text-robot-dark">Evaluation: In Silico vs. In Vitro Performance</h2>
                
                <div class="md:flex md:space-x-10 items-start">
                    
                    <div class="md:w-1/2 mb-8 md:mb-0 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-gold">In Vitro Results & Transferability</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            The critical test involved deploying the SAC + DROPO policy (optimized with CMA-ES) to the physical vascular phantoms.
                        </p>
                        
                        <!-- Sim vs Vitro Rollout Image -->
                        <div class="mt-4 mb-4 border border-gray-300 p-2 rounded-lg bg-white shadow-md">
                            <img src="sim_vs_vitro_rollout.png" alt="Comparison of Simulated vs. In Vitro Rollout" class="w-full h-auto object-contain rounded-md shadow-md">
                            <p class="text-center text-sm text-gray-500 mt-2">Comparison of simulated (top) and in vitro (bottom) guidewire navigation sequences to the LCCA target.</p>
                        </div>
                        
                        <ul class="list-disc list-inside mt-4 ml-4 text-base text-gray-700">
                            <li><strong>LCCA Success:</strong> All policies successfully transferred and navigated to the Left Common Carotid Artery (LCCA).</li>
                            <li><strong>RCCA Challenge:</strong> No policy could successfully reach the more complex Right Common Carotid Artery (RCCA), highlighting limitations in current simulation fidelity for complex anatomies.</li>
                        </ul>
                    </div>

                    <div class="md:w-1/2 bg-white p-6 rounded-xl shadow-xl">
                        <h3 class="text-2xl font-semibold mt-0 mb-3 text-robot-gold">Comparative Benchmarking</h3>
                        <p class="text-lg text-gray-700 leading-relaxed">
                            DROPO proved superior at narrowing the Sim2Real gap compared to curriculum-only or hybrid methods.
                        </p>
                        <h4 class="text-xl font-semibold mt-4 text-robot-dark">Optimized Performance Metrics</h4>
                        <ul class="list-disc list-inside mt-2 ml-4 text-base text-gray-700">
                            <li><strong>Optimal Optimizer:</strong> CMA-ES was found to be the most effective strategy for the DROPO formulation, achieving the lowest parameter estimation error and fastest convergence.</li>
                            <li><strong>Policy Performance:</strong> SAC + DROPO achieved <strong>80% success rate</strong> in unseen simulation environments, significantly surpassing the baseline SAC (65%).</li>
                        </ul>
                        <p class="text-base text-gray-700 mt-4">
                            This systematic evaluation provides critical empirical evidence supporting the use of data-driven domain randomisation (DROPO) as the state-of-the-art method for enabling robust, clinically translatable autonomous robotic interventions.
                        </p>
                    </div>
                </div>
            </section>
        </div>
    </template>

    <!-- Project Footer -->
    <footer class="mt-16 py-8 px-4 md:px-8 bg-robot-dark text-white">
        <div class="max-w-7xl mx-auto text-center">
            <h3 class="text-2xl font-bold mb-2">Robotics & Control Systems Portfolio</h3>
            <p class="text-gray-400 max-w-4xl mx-auto">
                These five projects showcase a comprehensive skill set across modern robotics, including embedded systems, advanced kinematic planning, computer vision, and cutting-edge Sim2Real AI research.
            </p>
            <p class="text-sm mt-4 text-gray-500">&copy; 2025 Andrea Walker Perez. All rights reserved.</p>
        </div>
    </footer>

    <script>
        const project1Content = document.getElementById('project1-template').content;
        const project2Content = document.getElementById('project2-template').content;
        const project3Content = document.getElementById('project3-template').content;
        const project4Content = document.getElementById('project4-template').content;
        const project5Content = document.getElementById('project5-template').content;
        
        const contentContainer = document.getElementById('content-container');
        
        const navProject1 = document.getElementById('nav-project1');
        const navProject2 = document.getElementById('nav-project2');
        const navProject3 = document.getElementById('nav-project3');
        const navProject4 = document.getElementById('nav-project4');
        const navProject5 = document.getElementById('nav-project5');

        let currentPage = 'project1';

        function renderPage(pageName) {
            // Clear current content
            contentContainer.innerHTML = '';
            
            // Remove all active styles
            navProject1.classList.remove('bg-robot-blue/20');
            navProject2.classList.remove('bg-robot-green/20');
            navProject3.classList.remove('bg-robot-red/20');
            navProject4.classList.remove('bg-robot-purple/20');
            navProject5.classList.remove('bg-robot-gold/20');
            
            let contentToAppend;
            let separatorColor;

            // Clone and append new content based on selected page
            if (pageName === 'project1') {
                contentToAppend = project1Content;
                navProject1.classList.add('bg-robot-blue/20');
                separatorColor = '#3b82f6';
            } else if (pageName === 'project2') {
                contentToAppend = project2Content;
                navProject2.classList.add('bg-robot-green/20');
                separatorColor = '#059669';
            } else if (pageName === 'project3') {
                contentToAppend = project3Content;
                navProject3.classList.add('bg-robot-red/20');
                separatorColor = '#dc2626';
            } else if (pageName === 'project4') {
                contentToAppend = project4Content;
                navProject4.classList.add('bg-robot-purple/20');
                separatorColor = '#7c3aed';
            } else if (pageName === 'project5') {
                contentToAppend = project5Content;
                navProject5.classList.add('bg-robot-gold/20');
                separatorColor = '#d97706';
            }
            
            contentContainer.appendChild(contentToAppend.cloneNode(true));
            currentPage = pageName;
            window.scrollTo(0, 0); // Scroll to top on page switch
            
            // Apply separator color dynamically
            const separator = document.querySelector('#content-container .section-separator');
            if (separator) {
                separator.style.backgroundColor = separatorColor;
            }
        }

        // Event listeners for navigation
        navProject1.addEventListener('click', () => renderPage('project1'));
        navProject2.addEventListener('click', () => renderPage('project2'));
        navProject3.addEventListener('click', () => renderPage('project3'));
        navProject4.addEventListener('click', () => renderPage('project4'));
        navProject5.addEventListener('click', () => renderPage('project5'));

        // Initial render
        renderPage(currentPage);
    </script>

</body>
</html>